{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQCKYTnqb/4N0kw3C09DeO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzJX5x4Hd6mE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVyU3ScYZ3Hc"
      },
      "source": [
        "%%capture\n",
        "\n",
        "! pip install transformers pytorch-lightning --quiet\n",
        "! sudo apt -qq install git-lfs\n",
        "! git config --global credential.helper store"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFempth1zK0"
      },
      "source": [
        "import requests\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from getpass import getpass\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from requests.exceptions import HTTPError\n",
        "from io import BytesIO\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from huggingface_hub import HfApi, HfFolder, Repository, notebook_login\n",
        "from torch.utils.data import DataLoader\n",
        "from torchmetrics import Accuracy\n",
        "from torchvision.datasets import ImageFolder\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/SunflowerDiseaseClassification/new_dataset_v1/\n",
        "\n",
        "!pwd"
      ],
      "metadata": {
        "id": "eFeI4bgm5_Ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_r5KO0aMIsn"
      },
      "source": [
        "## Init Dataset and Split into Training and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4vCcep26Em6"
      },
      "source": [
        "data_dir = Path('train')\n",
        "print(data_dir)\n",
        "ds = ImageFolder(data_dir)\n",
        "indices = torch.randperm(len(ds)).tolist()\n",
        "n_val = math.floor(len(indices) * .15)\n",
        "train_ds = torch.utils.data.Subset(ds, indices[:-n_val])\n",
        "val_ds = torch.utils.data.Subset(ds, indices[-n_val:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABreTsYRoDzy"
      },
      "source": [
        "## Show Some Examples\n",
        "\n",
        "#### ‚ö†Ô∏è Note - The image search API isn't perfect ‚ö†Ô∏è\n",
        "\n",
        "You may need to go back, tweak your search terms, and repeat the cells above until the images shown below look good.\n",
        "\n",
        "A few bad images is OK, but if they are completely incorrect, you'll definitely want to try again with different terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbzsRQRe6iY5"
      },
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "num_examples_per_class = 5\n",
        "i = 1\n",
        "for class_idx, class_name in enumerate(ds.classes):\n",
        "    folder = ds.root / class_name\n",
        "    for image_idx, image_path in enumerate(sorted(folder.glob('*'))):\n",
        "        if image_path.suffix in ds.extensions:\n",
        "            image = Image.open(image_path)\n",
        "            plt.subplot(len(ds.classes), num_examples_per_class, i)\n",
        "            ax = plt.gca()\n",
        "            ax.set_title(\n",
        "                class_name,\n",
        "                size='xx-large',\n",
        "                pad=5,\n",
        "                loc='left',\n",
        "                y=0,\n",
        "                backgroundcolor='white'\n",
        "            )\n",
        "            ax.axis('off')\n",
        "            plt.imshow(image)\n",
        "            i += 1\n",
        "\n",
        "            if image_idx + 1 == num_examples_per_class:\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96LqcgYfLGc8"
      },
      "source": [
        "## Preparing Labels for Our Model's Config\n",
        "\n",
        "By adding `label2id` + `id2label` to our model's config, we'll get friendlier labels in the inference API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh0yxRKDGDd5"
      },
      "source": [
        "label2id = {}\n",
        "id2label = {}\n",
        "\n",
        "for i, class_name in enumerate(ds.classes):\n",
        "    label2id[class_name] = str(i)\n",
        "    id2label[str(i)] = class_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1aly6Vrx2mM"
      },
      "source": [
        "## Image Classification Collator\n",
        "\n",
        "To apply our transforms to images, we'll use a custom collator class. We'll initialize it using an instance of `ViTFeatureExtractor` and pass the collator instance to `torch.utils.data.DataLoader`'s `collate_fn` kwarg."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2n0Mf1u1ymf"
      },
      "source": [
        "class ImageClassificationCollator:\n",
        "    def __init__(self, feature_extractor):\n",
        "        self.feature_extractor = feature_extractor\n",
        " \n",
        "    def __call__(self, batch):\n",
        "        encodings = self.feature_extractor([x[0] for x in batch], return_tensors='pt')\n",
        "        encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
        "        return encodings "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62uFtK7LTcz"
      },
      "source": [
        "## Init Feature Extractor, Model, Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YovQELKD4Bu8"
      },
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    'google/vit-base-patch16-224-in21k',\n",
        "    num_labels=len(label2id),\n",
        "    label2id=label2id,\n",
        "    id2label=id2label\n",
        ")\n",
        "collator = ImageClassificationCollator(feature_extractor)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, collate_fn=collator, num_workers=2, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=8, collate_fn=collator, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEgf32rC7pQh"
      },
      "source": [
        "# Training\n",
        "\n",
        "‚ö° We'll use [PyTorch Lightning](https://pytorchlightning.ai/) to fine-tune our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIIRpEzW4LFo"
      },
      "source": [
        "class Classifier(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model, lr: float = 2e-5, **kwargs):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters('lr', *list(kwargs))\n",
        "        self.model = model\n",
        "        self.forward = self.model.forward\n",
        "        self.val_acc = Accuracy(\n",
        "            task='multiclass' if model.config.num_labels > 2 else 'binary',\n",
        "            num_classes=model.config.num_labels\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        self.log(f\"train_loss\", outputs.loss)\n",
        "        return outputs.loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self(**batch)\n",
        "        self.log(f\"val_loss\", outputs.loss)\n",
        "        acc = self.val_acc(outputs.logits.argmax(1), batch['labels'])\n",
        "        self.log(f\"val_acc\", acc, prog_bar=True)\n",
        "        return outputs.loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWYA1rf3Heg"
      },
      "source": [
        "pl.seed_everything(42)\n",
        "classifier = Classifier(model, lr=2e-5)\n",
        "trainer = pl.Trainer(accelerator='gpu', devices=1, precision=16, max_epochs=50)\n",
        "trainer.fit(classifier, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJLxkmefLZT0"
      },
      "source": [
        "## Check if it Worked üòÖ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDfUUwH73LSq"
      },
      "source": [
        "val_batch = next(iter(val_loader))\n",
        "outputs = model(**val_batch)\n",
        "print('Preds: ', outputs.logits.softmax(1).argmax(1))\n",
        "print('Labels:', val_batch['labels'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric2 = load_metric(\"f1\")\n",
        "    \n",
        "    logits, labels = eval_pred\n",
        "    # predictions = np.argmax(logits, axis=-1)\n",
        "    predictions = outputs.logits.softmax(1).argmax(1)\n",
        "    labels = val_batch['labels']\n",
        "    precision = metric1.compute(predictions=predictions, references=labels)[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels)[\"recall\"]\n",
        "    return {\"precision\": precision, \"recall\": recall}"
      ],
      "metadata": {
        "id": "f-fGHMXrgwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FlEoisI9S-e"
      },
      "source": [
        "# Push to ü§ó Hub üöÄ\n",
        "\n",
        "You'll need to authenticate with your Hugging Face account, so make sure to [sign up](https://huggingface.co/join) if you haven't already.\n",
        "\n",
        "Your repo will be created at `{hf_username}/{model_id}`, so pick a `model_id` you like üòä"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "d1t_A7PkNRiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t58j9AN-iELM"
      },
      "source": [
        "model_id = \"sunflowerDiseaseClassification\" #@param {type:\"string\"}\n",
        "\n",
        "description = \"\"\"\n",
        "Autogenerated by HuggingPicsü§óüñºÔ∏è\n",
        "\n",
        "Create your own image classifier for **anything** by running [the demo on Google Colab](https://colab.research.google.com/github/nateraw/huggingpics/blob/main/HuggingPics.ipynb).\n",
        "\n",
        "Report any issues with the demo at the [github repo](https://github.com/nateraw/huggingpics).\n",
        "\"\"\"\n",
        "task_name = \"Image Classification\"\n",
        "task_type = 'image-classification'\n",
        "metric_name = 'Accuracy'\n",
        "metric_type = 'accuracy'\n",
        "metric_value = trainer.callback_metrics['val_acc'].item()\n",
        "\n",
        "# Delete model folder, as we (re)create it here.\n",
        "if Path('./model').exists():\n",
        "    shutil.rmtree('./model')\n",
        "\n",
        "token = HfFolder().get_token()\n",
        "if not token:\n",
        "    raise RuntimeError(\"You must log in to push to hub! Run notebook_login() in the cell above.\")\n",
        "\n",
        "hf_username = HfApi().whoami()['name']\n",
        "model_url = HfApi().create_repo(token=token, repo_id=model_id, exist_ok=True)\n",
        "model_repo = Repository(\"./model\", clone_from=model_url, use_auth_token=token, git_email=f\"{hf_username}@users.noreply.huggingface.co\", git_user=hf_username)\n",
        "model.save_pretrained(model_repo.local_dir)\n",
        "feature_extractor.save_pretrained(model_repo.local_dir)\n",
        "\n",
        "# Copy over tensorboard logs from lightning_logs/ into ./model/runs/\n",
        "tensorboard_logs_path = next(Path(trainer.logger.log_dir).glob('events.out*'))\n",
        "model_repo_logs_path = Path(model_repo.local_dir) / 'runs'\n",
        "model_repo_logs_path.mkdir(exist_ok=True, parents=True)\n",
        "shutil.copy(tensorboard_logs_path, model_repo_logs_path)\n",
        "\n",
        "# Copy over a few example images\n",
        "example_images_dir = Path(model_repo.local_dir) / 'images'\n",
        "example_images_dir.mkdir(exist_ok=True, parents=True)\n",
        "image_markdown_template = '''\n",
        "#### {class_name}\n",
        "\n",
        "![{class_name}](images/{example_image_path})\n",
        "'''\n",
        "example_images_markdown = \"\"\n",
        "for class_idx, class_name in enumerate(ds.classes):\n",
        "    folder = ds.root / class_name\n",
        "    image_path = sorted(folder.glob('*'))[0]\n",
        "    example_image_path = example_images_dir / f\"{class_name.replace(' ', '_')}{image_path.suffix}\"\n",
        "    shutil.copy(image_path, example_image_path)\n",
        "    example_images_markdown += image_markdown_template.format(\n",
        "        class_name=class_name,\n",
        "        example_image_path=example_image_path.name\n",
        "    )\n",
        "\n",
        "\n",
        "# Prepare README.md from information gathered above\n",
        "readme_txt = f\"\"\"\n",
        "---\n",
        "tags:\n",
        "- image-classification\n",
        "- pytorch\n",
        "- huggingpics\n",
        "metrics:\n",
        "- {metric_type}\n",
        "\n",
        "model-index:\n",
        "- name: {model_id}\n",
        "  results:\n",
        "  - task:\n",
        "      name: {task_name}\n",
        "      type: {task_type}\n",
        "    metrics:\n",
        "      - name: {metric_name}\n",
        "        type: {metric_type}\n",
        "        value: {metric_value}\n",
        "---\n",
        "\n",
        "# {model_id}\n",
        "\n",
        "{description}\n",
        "\n",
        "## Example Images\n",
        "\n",
        "{example_images_markdown}\n",
        "\n",
        "\"\"\".strip()\n",
        "\n",
        "(Path(model_repo.local_dir) / 'README.md').write_text(readme_txt)\n",
        "\n",
        "commit_url = model_repo.push_to_hub()\n",
        "\n",
        "print(\"Check out your model at:\")\n",
        "print(f\"https://huggingface.co/{hf_username}/{model_id}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}